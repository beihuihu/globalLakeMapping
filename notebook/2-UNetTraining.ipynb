{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen\n",
    "  \n",
    "  Modified by Xuehui Pi, Qiuqi Luo and Beihui Hu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Define the paths for the dataset and trained models in the `notebooks/config/UNetTraining.py` file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '16'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = '16'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '16'\n",
    "print(os.environ.get('OMP_NUM_THREADS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from tensorflow.keras import mixed_precision \n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet import UNet \n",
    "from core.losses import accuracy, dice_loss, IoU, recall, precision,F1_score\n",
    "from core.optimizers import adaDelta\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.visualize import display_images\n",
    "\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Mixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory.\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/UNetTraining.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    "# hbh: in this scene,a new config named UNetTraining_sequential is created to distinguish from the original\n",
    "from config import UNetTraining\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import UNetTraining\n",
    "config = UNetTraining.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgs(path_to_write, fn):\n",
    "    image = rasterio.open(os.path.join(path_to_write, fn))\n",
    "    read_image = image.read()\n",
    "    comb_img = np.transpose(read_image, axes=(1,2,0))\n",
    "    annotation_im = Image.open(os.path.join(path_to_write, fn.replace(config.image_fn,config.annotation_fn).replace(config.image_type,config.ann_type)))\n",
    "    annotation = np.array(annotation_im)\n",
    "    patch_count=annotation.shape[0]*annotation.shape[1]/(config.input_shape[0]*config.input_shape[1])\n",
    "    f = FrameInfo(comb_img, annotation)\n",
    "    return f,patch_count\n",
    "\n",
    "def readFrames(dataType):\n",
    "    frames=[]\n",
    "    patch_count_list=[] \n",
    "    print(dataType)\n",
    "    dataset_dir=os.path.join(config.dataset_dir,'{}'.format(dataType))\n",
    "    all_files = os.listdir(dataset_dir)\n",
    "    all_files_image = [fn for fn in all_files if fn.startswith(config.image_fn) and fn.endswith(config.image_type)]\n",
    "    for j, fn in enumerate(all_files_image):\n",
    "        f,pc = readImgs(dataset_dir,fn)\n",
    "        frames.append(f)\n",
    "        patch_count_list.append(pc)\n",
    "    return frames,patch_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read images for training, calculate the percentage of each image to be selected while use random strategy\n",
    "frames,patch_count_list=readFrames('train')\n",
    "patch_count_list=np.array(patch_count_list)\n",
    "train_patch_count=patch_count_list.sum()\n",
    "percentages=patch_count_list/train_patch_count\n",
    "print('total training image count:'+str(len(frames)))\n",
    "train_generator = DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = 'iaa').random_generator(config.BATCH_SIZE,percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images for validation, calculate the percentage of each image to be selected while use random strategy\n",
    "frames,patch_count_list=readFrames('val')\n",
    "patch_count_list=np.array(patch_count_list)\n",
    "val_patch_count=patch_count_list.sum()\n",
    "percentages=patch_count_list/val_patch_count\n",
    "print('total validation image count:'+str(len(frames)))\n",
    "val_generator = DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None).random_generator(config.BATCH_SIZE,percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read images for test, calculate the percentage of each image to be selected while use random strategy\n",
    "frames,patch_count_list=readFrames('test')\n",
    "patch_count_list=np.array(patch_count_list)\n",
    "test_patch_count=patch_count_list.sum()\n",
    "percentages=patch_count_list/test_patch_count\n",
    "print('total test image count:'+str(len(frames)))\n",
    "test_generator=DataGenerator(config.input_image_channel, config.patch_size, frames, config.input_label_channel, augmenter = None).random_generator(config.BATCH_SIZE,percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    train_images, real_label = next(train_generator) \n",
    "    display_images(np.concatenate((train_images,real_label), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    val_images, val_label = next(val_generator) \n",
    "    display_images(np.concatenate((val_images,val_label), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    test_images, real_label = next(test_generator) \n",
    "    display_images(np.concatenate((test_images,real_label), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER =  mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "\n",
    "LOSS=dice_loss\n",
    "LOSS_NAME = 'dice_loss'\n",
    "\n",
    "#Declare the path to the final model\n",
    "#If you want to retrain an exising model then change the cell where model is declared. \n",
    "# This path is for storing a model after training.\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '') \n",
    "\n",
    "if not os.path.exists(config.model_path):\n",
    "    os.makedirs(config.model_path)\n",
    "model_name='{}_{}_{}_{}_{}.h5'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs,config.input_shape[0])\n",
    "model_path = os.path.join(config.model_path,'lakes_'+model_name)\n",
    "\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '') \n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the model and compile it  \n",
    "model = UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[accuracy, recall, precision,F1_score, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks      for the early stopping of training, LearningRateScheduler and model checkpointing \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "#reduceonplatea： It can be useful when using adam as optimizer\n",
    "#Reduce learning rate when a metric has stopped improving (after some patience 个epoch, reduce by a factor of 0.33, new_lr = lr * factor). \n",
    "#cooldown: number of epochs to wait before resuming normal operation after lr has been reduced. \n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=4, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=4, min_lr=1e-16) \n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=50)\n",
    "\n",
    "\n",
    "log_dir = os.path.join('./logs','UNet_'+model_name)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard, early] #reduceLROnPlat is not required with adaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_history = model.fit(train_generator, \n",
    "                         steps_per_epoch=config.steps_per_epoch,\n",
    "                         epochs=config.NB_EPOCHS, \n",
    "                         validation_data=val_generator,\n",
    "                         validation_steps=config.validation_steps,\n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model after training \n",
    "model = load_model(model_path, custom_objects={'dice loss': LOSS, 'accuracy':accuracy ,'recall':recall, 'precision':precision,'F1_score':F1_score,'IoU': IoU,}, compile=False) \n",
    "\n",
    "# # In case you want to use multiple GPU you can uncomment the following lines.\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], cross_device_ops=tf.distribute.ReductionToOneDevice())\n",
    "# print('Number of devices: %d' % strategy.num_replicas_in_sync)\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[accuracy,recall,F1_score, precision, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=['ndwi','rgb','swir','annotation','prediction']\n",
    "for i in range(1):\n",
    "    test_images, real_label = next(test_generator)\n",
    "    prediction = model.predict(test_images, steps=1)\n",
    "    prediction[prediction>0.5]=1\n",
    "    prediction[prediction<=0.5]=0\n",
    "    display_images(np.concatenate((test_images, real_label, prediction), axis = -1),titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOeYCBzQRMr8FXNUC8za+ng",
   "collapsed_sections": [],
   "name": "step3-Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_gpu_38",
   "language": "python",
   "name": "tf_gpu_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
