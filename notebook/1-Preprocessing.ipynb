{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen\n",
    "  \n",
    "  Modified by Xuehui Pi , Qiuqi Luo and Beihui Hu\n",
    "\n",
    "\n",
    "#*************************************************************************************************************\n",
    "\n",
    "Copyright (c) 2020, Ankit Kariryaa\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.s\n",
    "\n",
    "#*************************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview \n",
    "\n",
    "The code was written by Ankit Kariryaa (Kariryaa AT uni-bremen DOT de) in 2018 (see https://doi.org/10.5281/zenodo.3978185), and some modifications were made by Xuehui Pi and Qiuqi Luo in 2020, some modifications were made by Beihui Hu in 2024,.\n",
    "\n",
    "Start by labeling a part of the satellite images with the lakes and storing the labels in shapefiles. The areas that are labeled are denoted by the 'training area' and actual lakes in that area are denoted by the 'training polygons'.\n",
    "\n",
    "- First, we read the training area and the training polygons from two separate shapefiles. Then we determine the training area for each training polygon. \n",
    "- Next, we read the parameters of each training area,for each area, parameter 'id' means the id of raw satellite image, 'type' means the region type of this area, 'file name' means the suffix file name of saved images.\n",
    "- Finally, we read and clip the raw satellite image (mean-NDWI,mean-B4,mean-B3,mean-B2,mea-B11) of each area, obtain the corresponding image files and label files, and store them into three subfolders ('train', 'test' and 'val') based on the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gps\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "from rasterio import features\n",
    "from shapely.geometry import box\n",
    "\n",
    "import numpy as np      \n",
    "import os\n",
    "from core.visualize import display_images\n",
    "\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/Preprocessing.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    "# hbh: in this scene,a new config named Preprocessing_within is created to distinguish from the original\n",
    "from config import Preprocessing   \n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import Preprocessing\n",
    "config = Preprocessing.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hbh: check whether the output dir(must be present) of each type is empty\n",
    "for dataset in ['train','test','val']:\n",
    "    dataset_dir=os.path.join(config.dataset_dir,'{}'.format(dataset))\n",
    "    os.makedirs(dataset_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the training area „ÄÅ training polygons\n",
    "trainingArea = gps.read_file(os.path.join(config.training_base_dir, config.training_area_fn))\n",
    "trainingPolygon = gps.read_file(os.path.join(config.training_base_dir, config.training_polygon_fn))\n",
    "\n",
    "print(trainingPolygon.shape,trainingArea.shape)# area:id, geomerry;   polygon:id, geometry \n",
    "trainingPolygon\n",
    "trainingArea\n",
    "print(f'Read a total of {trainingPolygon.shape[0]} object polygons and {trainingArea.shape[0]} training areas.')\n",
    "print(f'Polygons will be assigned to training areas in the next steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPolygon=trainingPolygon[trainingPolygon['dataset']=='test']\n",
    "trainingArea=trainingArea[trainingArea['dataset']=='test']\n",
    "trainingArea=trainingArea[-1:]\n",
    "trainingArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the training areas and the training polygons have the same crs     \n",
    "if trainingArea.crs  != trainingPolygon.crs:\n",
    "    print('Training area CRS does not match training_polygon CRS')\n",
    "    targetCRS = trainingPolygon.crs #Areas are less in number so conversion should be faster\n",
    "    trainingArea = trainingArea.to_crs(targetCRS)\n",
    "print(trainingPolygon.crs)\n",
    "print(trainingArea.crs)\n",
    "assert trainingPolygon.crs == trainingArea.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As input we received two shapefile, first one contains the training areas/rectangles and other contains the polygon of lakes/objects in those training areas\n",
    "# The first task is to determine the parent training area for each polygon.\n",
    "\n",
    "def dividePolygonsInTrainingAreas(trainingPolygon, trainingArea):\n",
    "    '''Assign annotated ploygons in to the training areas.'''\n",
    "    # For efficiency, assigned polygons are removed from the list, we make a copy here. \n",
    "    cpTrainingPolygon = trainingPolygon.copy()\n",
    "    splitPolygons = {}\n",
    "    for i in tqdm(trainingArea.index):\n",
    "        spTemp = [] \n",
    "        allocated = []\n",
    "        print(\"area's index:\",i)\n",
    "        for j in cpTrainingPolygon.index:\n",
    "            if cpTrainingPolygon.loc[j]['geometry'].intersects(trainingArea.loc[i]['geometry']):\n",
    "                spTemp.append(cpTrainingPolygon.loc[j])\n",
    "                allocated.append(j)      \n",
    "        splitPolygons[i] = {'polygons':spTemp,'bounds':list(trainingArea.bounds.loc[i]),'type':trainingArea.loc[i]['type'],'dataset':trainingArea.loc[i]['dataset'],'grid_id':trainingArea.loc[i]['grid_id'] ,'file_name':trainingArea.loc[i]['file_name'] }\n",
    "        cpTrainingPolygon = cpTrainingPolygon.drop(allocated)#assigned polygons are removed from the list\n",
    "    return splitPolygons\n",
    "\n",
    "# areasWithPolygons contains the object polygons for each area!\n",
    "areasWithPolygons = dividePolygonsInTrainingAreas(trainingPolygon, trainingArea)\n",
    "print(f'Assigned training polygons in {len(areasWithPolygons)} training areas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(areasWithPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAreasThatOverlapWithTrainingData(areaInfo, writePath):\n",
    "    \"\"\"Iterates over raw NDWI images and using findOverlap() extract areas that overlap with training data. \n",
    "    The overlapping areas in raw images are written in a separate file, and annotation file are created from polygons in the overlapping areas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(writePath):\n",
    "        os.makedirs(writePath)\n",
    "        \n",
    "    polygonsInAreaDf = gps.GeoDataFrame(areaInfo['polygons'])\n",
    "    grid_id=str(areaInfo['grid_id'])\n",
    "    file_name=str(areaInfo['file_name'])\n",
    "    print(grid_id)\n",
    "    bboxArea = box(*areaInfo['bounds'])\n",
    "    t=str(areaInfo['type'])\n",
    "\n",
    "    #draw image png\n",
    "    Img = rasterio.open(os.path.join(config.raw_image_base_dir,f'{config.raw_image_prefix}_{grid_id}{config.image_type}'))  \n",
    "    sm_img = rasterio.mask.mask(Img, [bboxArea], all_touched=True, crop=True )\n",
    "    profile_img = Img.profile  \n",
    "    profile_img['height'] = sm_img[0].shape[1]\n",
    "    profile_img['width'] = sm_img[0].shape[2]\n",
    "    profile_img['transform'] = sm_img[1]\n",
    "        # That's a problem with rasterio, if the height and the width are less then 256 it throws: ValueError: blockysize exceeds raster height \n",
    "        # So set the blockxsize and blockysize to prevent this problem\n",
    "    profile_img['blockxsize'] = 32\n",
    "    profile_img['blockysize'] = 32\n",
    "    profile_img['dtype'] = rasterio.float32    \n",
    "    profile_img['compress'] = 'lzw'\n",
    "    profile_img['tiled'] = 'True'\n",
    "    profile_img['nodata'] =None\n",
    "    print(profile_img) \n",
    "    # To save storage space, image values were retained to three decimal places and multiplied by 1000 before being stored in integer format.\n",
    "    # Here, the values are converted back to floating point.\n",
    "    \n",
    "    dt_img = sm_img[0].astype(profile_img['dtype'])\n",
    "    with rasterio.open(os.path.join(writePath, f'{config.extracted_image_filename}{t}_{file_name}{config.image_type}'), 'w', **profile_img) as dst:\n",
    "        dst.write(dt_img) \n",
    "\n",
    "#     draw annotation png\n",
    "    polygons = []\n",
    "    for i in polygonsInAreaDf.index:\n",
    "        gm = polygonsInAreaDf.loc[i]['geometry']\n",
    "        polygons.append(gm)\n",
    "    profile_img['count'] = 1    \n",
    "    with rasterio.open(os.path.join(writePath,f'{config.extracted_annotation_filename}{t}_{file_name}{config.ann_type}'), 'w+', **profile_img) as out:\n",
    "        out_arr = out.read(1)\n",
    "        burned = features.rasterize(polygons, fill=0, default_value=1,out=out_arr, transform=out.transform)\n",
    "        out.write_band(1, burned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in zip(areasWithPolygons.keys(),areasWithPolygons.values()):\n",
    "    dataset_dir=os.path.join(config.dataset_dir,r'{}'.format(value['dataset']))\n",
    "    extractAreasThatOverlapWithTrainingData(value,dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted image \n",
    "file_name = ''\n",
    "dataset_dir=os.path.join(config.dataset_dir,r'test' )\n",
    "img_fn = os.path.join(dataset_dir, f'{config.extracted_image_filename}{file_name}{config.image_type}')\n",
    "img = rasterio.open(img_fn)\n",
    "read_img = img.read()\n",
    "\n",
    "ann_fn=os.path.join(dataset_dir, f'{config.extracted_annotation_filename}{file_name}{config.ann_type}')\n",
    "ann=rasterio.open(ann_fn)\n",
    "read_annotation = ann.read()\n",
    "comb_img=np.concatenate((read_img,read_annotation), axis=0)\n",
    "comb_img=np.transpose(comb_img, axes=(1,2,0))\n",
    "# print(read_annotation.shape)\n",
    "# print(read_annotation)\n",
    "\n",
    "print(comb_img.shape)\n",
    "display_images(np.expand_dims(comb_img, axis=0),titles=['ndwi','rgb','swir','annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLAKESplus_env",
   "language": "python",
   "name": "glakesplus_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
