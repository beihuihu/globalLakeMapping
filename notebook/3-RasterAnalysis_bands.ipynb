{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Ankit Kariryaa, University of Bremen.\n",
    "\n",
    "Modified by Xuehui Pi, Qiuqi Luo and Beihui Hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import mixed_precision \n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "import numpy as np               # numerical array manipulation\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from core.losses import accuracy, dice_loss, IoU, recall, precision,F1_score\n",
    "from core.optimizers import adaDelta\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/RasterAnalysis.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import RasterAnalysis_bands\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import RasterAnalysis\n",
    "config = RasterAnalysis_bands.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model \n",
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER=mixed_precision.LossScaleOptimizer(OPTIMIZER)\n",
    "model = load_model(config.trained_model_path, custom_objects={'dice loss': dice_loss, 'accuracy':accuracy ,'recall':recall, 'F1_score':F1_score,'precision':precision,'IoU': IoU}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=dice_loss, metrics=[dice_loss, accuracy,recall, precision, IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch   to    the total results of a larger area. \n",
    "#The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "#res:mask [rows,cols] predition=np.squeeze(prediction[i], axis = -1) (col, row, wi, he) = batch_pos[i]\n",
    "def addTOResult(res, prediction, row, col, he, wi,ie_width,operator):\n",
    "    currValue = res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width]\n",
    "    newPredictions = prediction[ie_width:he-ie_width, ie_width:wi-ie_width]\n",
    "    \n",
    "# IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! \n",
    "#If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if operator == 'min': # Takes the min of current prediction and new prediction for each pixel  \n",
    "        currValue [currValue == -1] = 1 #Replace -1 with 1 in case of MIN  \n",
    "        res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width] = np.minimum(currValue, newPredictions)\n",
    "    elif operator == 'max':\n",
    "        res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width] = np.maximum(currValue, newPredictions)\n",
    "    else:\n",
    "        res[row+ie_width:row+he-ie_width, col+ie_width:col+wi-ie_width] = newPredictions  \n",
    "#     print(res.max())\n",
    "#     print(newPredictions.max())\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask,ie_width,operator):\n",
    "    tm = np.stack(batch, axis = 0)\n",
    "    prediction = model.predict(tm)\n",
    "#     fn=r'D:\\lakemapping\\2_dataset\\test\\test.png'\n",
    "#     display_images(np.concatenate((tm, prediction), axis = -1),fn=fn)\n",
    "    for i in range(len(batch_pos)): \n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis = -1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi,ie_width,operator)  \n",
    "    return mask\n",
    "\n",
    "def detect_lake(image ,width=576, height=576, stride = 376,ie_width=100,bandNum=5):\n",
    "    nols, nrows = image.meta['width'], image.meta['height']\n",
    "    meta = image.meta.copy() \n",
    "    if 'float' not in meta['dtype']: #The prediction is a float so we keep it as float to be consistent with the prediction. \n",
    "        meta['dtype'] = np.float32\n",
    "    meta['count'] = 1\n",
    "    col_index=list(range(0, nols-width, stride))\n",
    "    col_index.append(nols-width)\n",
    "    row_index=list(range(0, nrows-height, stride))\n",
    "    row_index.append(nrows-height)\n",
    "    offsets = product(col_index,row_index)\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    print('the size of current image',nrows, nols) \n",
    "    mask = np.zeros((nrows, nols), dtype=meta['dtype'])\n",
    "\n",
    "#     mask = mask -1   # Note: The initial mask is initialized with -1 instead of zero   to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = [ ]\n",
    "    for col_off, row_off in  tqdm(offsets):\n",
    "        window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, image.transform) \n",
    "        patch = np.full((height, width, bandNum),-1.0)#Add -1 padding in case of corner images\n",
    "        read_img = image.read(window=window)/1000\n",
    "        read_img =  np.transpose(read_img, axes=(1,2,0))\n",
    "\n",
    "        patch[:window.height, :window.width] = read_img   \n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        \n",
    "        if (len(batch) == config.BATCH_SIZE):\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask,ie_width,'max')\n",
    "#             print(mask.max()) \n",
    "            batch = []\n",
    "            batch_pos = []   \n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask,ie_width,'max')\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return(mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeMaskToDisk(detected_mask, detected_meta, wp, write_as_type = 'uint8', th = 0.5, create_countors = False):\n",
    "    # Convert to correct required before writing\n",
    "    if 'float' in str(detected_meta['dtype']) and 'int' in write_as_type:\n",
    "        print(f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}')#float32 to uint8\n",
    "#         initial code have problem of big lake\n",
    "        detected_mask[detected_mask<th]=0\n",
    "        detected_mask[detected_mask>=th]=1\n",
    "        detected_mask = detected_mask.astype(write_as_type)#'uint8'\n",
    "        detected_meta['dtype'] =  write_as_type\n",
    "    \n",
    "    # compress tif\n",
    "    detected_meta.update({\"compress\": 'lzw'})\n",
    "    \n",
    "    with rasterio.open(wp, 'w', **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for root, dirs, files in os.walk(config.input_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(config.input_image_type) and file.startswith(config.image_fn_st):\n",
    "             all_files.append((os.path.join(root, file), file))\n",
    "# print(all_files)\n",
    "\n",
    "for fullPath, filename in all_files:\n",
    "    outputFile=os.path.join(config.output_dir,filename.replace(config.image_fn_st, config.output_prefix) )\n",
    "    if not os.path.isfile(outputFile) or config.overwrite_analysed_files: \n",
    "        with rasterio.open(fullPath) as image:\n",
    "            print(fullPath)\n",
    "            detectedMask, detectedMeta = detect_lake(image,width = config.WIDTH, height = config.HEIGHT, stride = config.STRIDE,ie_width=config.ignore_edge_width,bandNum=config.band_num)\n",
    "            writeMaskToDisk(detectedMask, detectedMeta, outputFile, write_as_type = config.output_dtype, th = 0.5, create_countors = False)            \n",
    "        print('File already analysed!', fullPath)\n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLAKESplus_env",
   "language": "python",
   "name": "glakesplus_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
